{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import corpus here\n",
    "# nltk.download() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am using only 5 of the categories from the Brown corpus to keep my total amount of data low enough to work on my local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_adventure = brown.sents(categories='adventure')\n",
    "raw_lore = brown.sents(categories='lore')\n",
    "raw_mystery = brown.sents(categories='mystery')\n",
    "raw_romance = brown.sents(categories='romance')\n",
    "raw_science_fiction = brown.sents(categories='science_fiction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4637\n",
      "4881\n",
      "3886\n",
      "4431\n",
      "948\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_adventure))\n",
    "print(len(raw_lore))\n",
    "print(len(raw_mystery))\n",
    "print(len(raw_romance))\n",
    "print(len(raw_science_fiction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am dropping the science fiction label because of the drastic difference in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_adventure = [\" \".join(sent) for sent in raw_adventure]\n",
    "joined_lore = [\" \".join(sent) for sent in raw_lore]\n",
    "joined_mystery = [\" \".join(sent) for sent in raw_mystery]\n",
    "joined_romance = [\" \".join(sent) for sent in raw_romance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "table = str.maketrans({key:None for key in punctuation})\n",
    "cleaned_adventure = [sent.translate(table) for sent in joined_adventures]\n",
    "cleaned_lore = [sent.translate(table) for sent in joined_lore]\n",
    "cleaned_mystery = [sent.translate(table) for sent in joined_mystery]\n",
    "cleaned_romance = [sent.translate(table) for sent in joined_romance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dan Morgan told himself he would forget Ann Turner '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_adventure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan Morgan told himself he would forget Ann Tu...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He was well rid of her</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He certainly didnt want a wife who was fickle ...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If he had married her  hed have been asking fo...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But all of this was rationalization</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1\n",
       "0  Dan Morgan told himself he would forget Ann Tu...  adventure\n",
       "1                            He was well rid of her   adventure\n",
       "2  He certainly didnt want a wife who was fickle ...  adventure\n",
       "3  If he had married her  hed have been asking fo...  adventure\n",
       "4               But all of this was rationalization   adventure"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adventure_sents = [[sent, \"adventure\"] for sent in cleaned_adventure]\n",
    "lore_sents = [[sent, \"lore\"] for sent in cleaned_lore]\n",
    "mystery_sents = [[sent, \"mystery\"] for sent in cleaned_mystery]\n",
    "romance_sents = [[sent, \"romance\"] for sent in cleaned_romance]\n",
    "\n",
    "sentences = pd.DataFrame(adventure_sents +\n",
    "                         lore_sents +\n",
    "                         mystery_sents +\n",
    "                         romance_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 3000 most common words.\n",
    "# changed word cound from 2000 to 200 because we aren't comparing works from\n",
    "# two different authors but from 5 different genres.\n",
    "\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # make text string, pull out each word\n",
    "    text = str(text)\n",
    "    allwords = text.split()\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(200)]\n",
    "    \n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        sentence = nlp(sentence)\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "adventure_words = bag_of_words(cleaned_adventure)\n",
    "print(len(adventure_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lore_words = bag_of_words(cleaned_lore)\n",
    "mystery_words = bag_of_words(cleaned_mystery)\n",
    "romance_words = bag_of_words(cleaned_romance)\n",
    "\n",
    "common_words = set(adventure_words +\n",
    "                   lore_words +\n",
    "                   mystery_words +\n",
    "                   romance_words)\n",
    "\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 1000\n",
      "Processing row 2000\n",
      "Processing row 3000\n",
      "Processing row 4000\n",
      "Processing row 5000\n",
      "Processing row 6000\n",
      "Processing row 7000\n",
      "Processing row 8000\n",
      "Processing row 9000\n",
      "Processing row 10000\n",
      "Processing row 11000\n",
      "Processing row 12000\n",
      "Processing row 13000\n",
      "Processing row 14000\n",
      "Processing row 15000\n",
      "Processing row 16000\n",
      "Processing row 17000\n",
      "Processing row 18000\n",
      "Processing row 19000\n",
      "Processing row 20000\n",
      "Processing row 21000\n",
      "Processing row 22000\n"
     ]
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make tf-idf df\n",
    "\n",
    "### I am combining the texts all together before splitting the paragraphs apart because I cannot feed them to the vectorizer if I join them after splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\tDan/np Morgan/np told/vbd himself/ppl he/pps would/md forget/vb Ann/np Turner/np ./.\\nHe/pps was/bedz well/rb rid/jj of/in her/ppo ./.\\nHe/pps certainly/rb didn't/dod* want/vb a/at wife/nn who/wps was/bedz fickle/jj as/cs Ann/np ./.\\nIf/cs he/pps had/hvd married/vbn her/ppo ,/, he'd/pps+md have/hv been/ben asking/vbg for/in trouble/nn ./.\""
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the texts then split into paragraphs\n",
    "adventure = brown.raw(categories='adventure')\n",
    "lore = brown.raw(categories='lore')\n",
    "mystery = brown.raw(categories='mystery')\n",
    "romance = brown.raw(categories='romance')\n",
    "\n",
    "combined2 = adventure + lore + mystery + romance\n",
    "combined2 = combined2.split('\\n\\n\\n\\t')\n",
    "combined2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length combined2:  4579\n",
      "length adventure:  1303\n",
      "length lore:  1042\n",
      "length mystery:  1080\n",
      "length romance:  1154\n",
      "adventure indicies should end at: 1303\n",
      "lore indicies should end at:  2345\n",
      "mystery indicies should end at:  3425\n",
      "romance indicies should end at: 4579\n"
     ]
    }
   ],
   "source": [
    "print('length combined2: ', len(combined2))\n",
    "print('length adventure: ', len(adventure.split('\\n\\n\\n\\t')))\n",
    "print('length lore: ', len(lore.split('\\n\\n\\n\\t')))\n",
    "print('length mystery: ', len(mystery.split('\\n\\n\\n\\t')))\n",
    "print('length romance: ', len(romance.split('\\n\\n\\n\\t')))\n",
    "\n",
    "print('adventure indicies should end at:', len(adventure.split('\\n\\n\\n\\t')))\n",
    "print('lore indicies should end at: ', len((adventure + lore).split('\\n\\n\\n\\t')))\n",
    "print('mystery indicies should end at: ', len((adventure + lore + mystery).split('\\n\\n\\n\\t')))\n",
    "print('romance indicies should end at:', len((adventure + lore + mystery + romance).split('\\n\\n\\n\\t')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 11652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.75, \n",
    "                             min_df=2,\n",
    "                             lowercase=False,\n",
    "                             use_idf=True,\n",
    "                             norm=u'l2',\n",
    "                             smooth_idf=True)\n",
    "\n",
    "\n",
    "# Applying the vectorizer\n",
    "brown_paras_tfidf=vectorizer.fit_transform(combined2)\n",
    "print(\"Number of features: %d\" % brown_paras_tfidf.get_shape()[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4579, 11652)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_paras_tfidf.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = (vectorizer.vocabulary_)\n",
    "feature_sorted = sorted(feature_names, key = feature_names.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorized_df = pd.DataFrame(data=brown_paras_tfidf.toarray(),\n",
    "                             index=np.arange(brown_paras_tfidf.shape[0]),\n",
    "                             columns=(feature_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorized_df['categories'] = None\n",
    "vectorized_df.loc[0:1303, 'categories'] = 'adventure'\n",
    "vectorized_df.loc[1303:2345, 'categories'] = 'lore'\n",
    "vectorized_df.loc[2345:3425, 'categories'] = 'mystery'\n",
    "vectorized_df.loc[3425:4579, 'categories'] = 'romance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up pipeline here\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "lr = LogisticRegression()\n",
    "\n",
    "svd= TruncatedSVD(200)\n",
    "logr_pipe = make_pipeline(svd, lr)\n",
    "forest_pipe = make_pipeline(svd, rfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8938867924528302\n",
      "\n",
      "Test set score: 0.28129952456418383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Bag-Of-Words supervised learning\n",
    "\n",
    "word_count_Y = word_counts['text_source']\n",
    "word_count_X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(word_count_X, \n",
    "                                                    word_count_Y,\n",
    "                                                    test_size=0.4)\n",
    "train = forest_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', forest_pipe.score(X_train, y_train))\n",
    "print('\\nTest set score:', forest_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.27274785, 0.27416799, 0.2808607 ])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Random Forest Train:')\n",
    "cross_val_score(forest_pipe, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25644505, 0.26299694, 0.24940537])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Random Forest Test:')\n",
    "cross_val_score(forest_pipe, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.38045283018867926\n",
      "\n",
      "Test set score: 0.34435136970794655\n",
      "\n",
      "Cross Validation: [0.33412483 0.34148828 0.33809038]\n"
     ]
    }
   ],
   "source": [
    "# Word Count Model\n",
    "train = logr_pipe.fit(X_train, y_train)\n",
    "print('Training set score:', logr_pipe.score(X_train, y_train))\n",
    "print('\\nTest set score:', logr_pipe.score(X_test, y_test))\n",
    "print('\\nCross Validation:', cross_val_score(logr_pipe, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF variable set up and split\n",
    "\n",
    "tfidf_X = vectorized_df.drop(labels='categories', axis=1)\n",
    "tfidf_y = vectorized_df.categories\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_X,\n",
    "                                                                            tfidf_y,\n",
    "                                                                            test_size=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2747, 11651) (2747,)\n",
      "TFIDF Training set score: 0.6690935566072078\n",
      "\n",
      " TFIDF Test set score: 0.5758733624454149\n",
      "\n",
      "Cross Validation [0.5245098  0.51554828 0.57635468]\n",
      "TFIDF Training set score: 0.9883509282854023\n",
      "\n",
      "TFIDF Test set score: 0.4443231441048035\n",
      "\n",
      "Cross Validation [0.43627451 0.4091653  0.42692939]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Model\n",
    "train = logr_pipe.fit(X_train_tfidf, y_train_tfidf)\n",
    "print(X_train_tfidf.shape, y_train_tfidf.shape)\n",
    "print('TFIDF Training set score:', logr_pipe.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\n TFIDF Test set score:', logr_pipe.score(X_test_tfidf, y_test_tfidf))\n",
    "print('\\nCross Validation', cross_val_score(logr_pipe, X_test_tfidf, y_test_tfidf))\n",
    "\n",
    "train = forest_pipe.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('TFIDF Training set score:', forest_pipe.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTFIDF Test set score:', forest_pipe.score(X_test_tfidf, y_test_tfidf))\n",
    "print('\\nCross Validation', cross_val_score(forest_pipe, X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4312340571673358"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest_pipe, X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4847459203658764"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest_pipe2, X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am upping the number of estimators in the random forest classifier to 100 from the default 10 to  attempt to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Training set score: 0.9996359665089188\n",
      "\n",
      "TFIDF Test set score: 0.5081877729257642\n",
      "\n",
      "Cross Validation: [0.47222222 0.49099836 0.47454844]\n"
     ]
    }
   ],
   "source": [
    "rfc2 = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "forest_pipe2 = make_pipeline(svd, rfc2)\n",
    "train = forest_pipe2.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('TFIDF Training set score:', forest_pipe2.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTFIDF Test set score:', forest_pipe2.score(X_test_tfidf, y_test_tfidf))\n",
    "print('\\nCross Validation:', cross_val_score(forest_pipe2, X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick recap of what I’ve done:\n",
    "\n",
    "I decided to use the Brown corpus because of the multitude of categories and also ease of access. I started by collecting the sentences from each category into variables and checking their length. I chose to drop the science fiction category because of its size difference. Next, I joined my sentences together. They were lists of words instead of a single string. I then stripped out the punctuation, and collected each sentence into a data frame, labeling each row with the coordinating category. Next, I used a small function to pull the 200 most common words out of each category and created a set of common words for my corpus. With the sentences and common words, I then made a feature set of the word count for each sentence. \n",
    "\n",
    "I then turned my attention to making a term frequency-inverse document frequency feature set. For this feature set, I pulled in the raw data for each category. I then figured out the length for each after splitting it into paragraphs and recorded where in the data frame each would fall. \n",
    "\n",
    "Unfortunately, I had to wait to set up the pipeline until after I’d vectorized the paragraphs so I could correctly label each one. Once the category labels were set, I used make_pipeline from the SKLearn module to set up two pipelines. Both reduce the feature space down to 200, but one then feeds into a RandomForestClassifier and the other into a LogisticRegression. \n",
    "\n",
    "The first model I ran was random forest using the word count feature set. The feature set was very over fit for the training data, and returned a score barely better than chance for the test data. The cross validated scores support and reinforce the low test score. The logistic regression did a fair bit better than the random forest. The training scores and test scores were much closer together for the logistic regression, and the cross validated scores were very close. \n",
    "\n",
    "With both models run, I decided to try to improve the Random Forest classifier. I changed the number of ‘trees’ from the default 10 up to 100 and saw a 5% increase in my accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
