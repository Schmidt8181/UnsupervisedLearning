{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import corpus here\n",
    "# nltk.download() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I chose to only use 5 categories in my work here because I did not want overload my kernel as I am on a MacBookAir and do not have unlimited space in memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_adventure = brown.sents(categories='adventure')\n",
    "raw_lore = brown.sents(categories='lore')\n",
    "raw_mystery = brown.sents(categories='mystery')\n",
    "raw_romance = brown.sents(categories='romance')\n",
    "raw_science_fiction = brown.sents(categories='science_fiction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4637\n",
      "4881\n",
      "3886\n",
      "4431\n",
      "948\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_adventure))\n",
    "print(len(raw_lore))\n",
    "print(len(raw_mystery))\n",
    "print(len(raw_romance))\n",
    "print(len(raw_science_fiction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_adventure = [\" \".join(sent) for sent in raw_adventure]\n",
    "joined_lore = [\" \".join(sent) for sent in raw_lore]\n",
    "joined_mystery = [\" \".join(sent) for sent in raw_mystery]\n",
    "joined_romance = [\" \".join(sent) for sent in raw_romance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "table = str.maketrans({key:None for key in punctuation})\n",
    "cleaned_adventure = [sent.translate(table) for sent in joined_adventures]\n",
    "cleaned_lore = [sent.translate(table) for sent in joined_lore]\n",
    "cleaned_mystery = [sent.translate(table) for sent in joined_mystery]\n",
    "cleaned_romance = [sent.translate(table) for sent in joined_romance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dan Morgan told himself he would forget Ann Turner '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_adventure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan Morgan told himself he would forget Ann Tu...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He was well rid of her</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He certainly didnt want a wife who was fickle ...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If he had married her  hed have been asking fo...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But all of this was rationalization</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1\n",
       "0  Dan Morgan told himself he would forget Ann Tu...  adventure\n",
       "1                            He was well rid of her   adventure\n",
       "2  He certainly didnt want a wife who was fickle ...  adventure\n",
       "3  If he had married her  hed have been asking fo...  adventure\n",
       "4               But all of this was rationalization   adventure"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adventure_sents = [[sent, \"adventure\"] for sent in cleaned_adventure]\n",
    "lore_sents = [[sent, \"lore\"] for sent in cleaned_lore]\n",
    "mystery_sents = [[sent, \"mystery\"] for sent in cleaned_mystery]\n",
    "romance_sents = [[sent, \"romance\"] for sent in cleaned_romance]\n",
    "\n",
    "sentences = pd.DataFrame(adventure_sents +\n",
    "                         lore_sents +\n",
    "                         mystery_sents +\n",
    "                         romance_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 3000 most common words.\n",
    "# changed word cound from 2000 to 200 because we aren't comparing works from\n",
    "# two different authors but from 5 different genres.\n",
    "\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # make text string, pull out each word\n",
    "    text = str(text)\n",
    "    allwords = text.split()\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(200)]\n",
    "    \n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        sentence = nlp(sentence)\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "adventure_words = bag_of_words(cleaned_adventure)\n",
    "print(len(adventure_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lore_words = bag_of_words(cleaned_lore)\n",
    "mystery_words = bag_of_words(cleaned_mystery)\n",
    "romance_words = bag_of_words(cleaned_romance)\n",
    "\n",
    "common_words = set(adventure_words +\n",
    "                   lore_words +\n",
    "                   mystery_words +\n",
    "                   romance_words)\n",
    "\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 1000\n",
      "Processing row 2000\n",
      "Processing row 3000\n",
      "Processing row 4000\n",
      "Processing row 5000\n",
      "Processing row 6000\n",
      "Processing row 7000\n",
      "Processing row 8000\n",
      "Processing row 9000\n",
      "Processing row 10000\n",
      "Processing row 11000\n",
      "Processing row 12000\n",
      "Processing row 13000\n",
      "Processing row 14000\n",
      "Processing row 15000\n",
      "Processing row 16000\n",
      "Processing row 17000\n",
      "Processing row 18000\n",
      "Processing row 19000\n",
      "Processing row 20000\n",
      "Processing row 21000\n",
      "Processing row 22000\n"
     ]
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make tf-idf df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\tDan/np Morgan/np told/vbd himself/ppl he/pps would/md forget/vb Ann/np Turner/np ./.\\nHe/pps was/bedz well/rb rid/jj of/in her/ppo ./.\\nHe/pps certainly/rb didn't/dod* want/vb a/at wife/nn who/wps was/bedz fickle/jj as/cs Ann/np ./.\\nIf/cs he/pps had/hvd married/vbn her/ppo ,/, he'd/pps+md have/hv been/ben asking/vbg for/in trouble/nn ./.\""
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the texts then split into paragraphs\n",
    "adventure = brown.raw(categories='adventure')\n",
    "lore = brown.raw(categories='lore')\n",
    "mystery = brown.raw(categories='mystery')\n",
    "romance = brown.raw(categories='romance')\n",
    "\n",
    "combined2 = adventure + lore + mystery + romance\n",
    "combined2 = combined2.split('\\n\\n\\n\\t')\n",
    "combined2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length combined2:  4579\n",
      "length adventure:  1303\n",
      "length lore:  1042\n",
      "length mystery:  1080\n",
      "length romance:  1154\n",
      "adventure indicies should end at: 1303\n",
      "lore indicies should end at:  2345\n",
      "mystery indicies should end at:  3425\n",
      "romance indicies should end at: 4579\n"
     ]
    }
   ],
   "source": [
    "print('length combined2: ', len(combined2))\n",
    "print('length adventure: ', len(adventure.split('\\n\\n\\n\\t')))\n",
    "print('length lore: ', len(lore.split('\\n\\n\\n\\t')))\n",
    "print('length mystery: ', len(mystery.split('\\n\\n\\n\\t')))\n",
    "print('length romance: ', len(romance.split('\\n\\n\\n\\t')))\n",
    "\n",
    "print('adventure indicies should end at:', len(adventure.split('\\n\\n\\n\\t')))\n",
    "print('lore indicies should end at: ', len((adventure + lore).split('\\n\\n\\n\\t')))\n",
    "print('mystery indicies should end at: ', len((adventure + lore + mystery).split('\\n\\n\\n\\t')))\n",
    "print('romance indicies should end at:', len((adventure + lore + mystery + romance).split('\\n\\n\\n\\t')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 11652\n",
      "Original sentence: His/pp$ wide/jj mouth/nn compressed/vbd ./.\n",
      "In/in a/at way/nn ,/, he/pps couldn't/md* blame/vb her/ppo ./.\n",
      "He/pps had/hvd picked/vbn out/rp this/dt pathless/jj trail/nn ,/, instead/rb of/in the/at common/jj one/pn ,/, in/in a/at moment/nn of/in romantic/jj fancy/nn ,/, to/to give/vb them/ppo privacy/nn on/in their/pp$ honeymoon/nn ./.\n",
      "Tf_idf vector: {'Rourke': 0.26470756380021243, 'Turn': 0.3309259034569111, 'yes': 0.24942003913473113, 'block': 0.2539129094404099, 'number': 0.2201980231343145, 'side': 0.18737929032726755, 'me': 0.13983816302168256, 'right': 0.16422020464324277, 'Not': 0.203283864413083, 'gave': 0.1997424307017251, 'better': 0.18801228385465538, 'you': 0.10971910456328318, 'hand': 0.17641586551449281, 'see': 0.15612680198525877, 'said': 0.11151776001878064, 'think': 0.1794094594878007, 'left': 0.17453467990730198, 'more': 0.1427050574923614, 'rbr': 0.14555883562445493, 'ppss': 0.13674271095634935, 'or': 0.1249068636787584, 'nr': 0.1422830664316856, 'than': 0.14949162277714884, 'ap': 0.09070970058051647, 'it': 0.08952817595214597, 'out': 0.11664426091499404, 'that': 0.08540343310014972, 'so': 0.13446799364146386, 'to': 0.06204145449549346, 'could': 0.13153688303889172, 'and': 0.061758780598560964, 'the': 0.10627219799617804, 'dt': 0.08558823057101159, 'cc': 0.11210074053301332, 'for': 0.09261086859108077, 'ppo': 0.13250102082732942, 'vb': 0.16626838671534067, 'md': 0.0764443234292975, 'pps': 0.05956469617801859, 'he': 0.08984972746100198, 'np': 0.05795208955929854}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test = train_test_split(combined2, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.75, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice, \n",
    "                             lowercase=False, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies. Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "brown_paras_tfidf=vectorizer.fit_transform(combined2)\n",
    "print(\"Number of features: %d\" % brown_paras_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(brown_paras_tfidf, test_size=0.4)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "print('Original sentence:', X_train[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4579, 11652)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_paras_tfidf.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = (vectorizer.vocabulary_)\n",
    "feature_sorted = sorted(feature_names, key = feature_names.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df = pd.DataFrame(data=brown_paras_tfidf.toarray(),\n",
    "                             index=np.arange(brown_paras_tfidf.shape[0]),\n",
    "                             columns=(feature_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df['categories'] = None\n",
    "vectorized_df.loc[0:1303, 'categories'] = 'adventure'\n",
    "vectorized_df.loc[1303:2345, 'categories'] = 'lore'\n",
    "vectorized_df.loc[2345:3425, 'categories'] = 'mystery'\n",
    "vectorized_df.loc[3425:4579, 'categories'] = 'romance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.888\n",
      "\n",
      "Test set score: 0.29431741000679196\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Bag-Of-Words supervised learning\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "word_count_Y = word_counts['text_source']\n",
    "word_count_X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(word_count_X, \n",
    "                                                    word_count_Y,\n",
    "                                                    test_size=0.4)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13250, 304) (13250,)\n",
      "Training set score: 0.3772075471698113\n",
      "\n",
      "Test set score: 0.34480416572334166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF supervised learning \n",
    "\n",
    "tfidf_X = vectorized_df.drop(labels='categories', axis=1)\n",
    "tfidf_y = vectorized_df.categories\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_X,\n",
    "                                                                            tfidf_y,\n",
    "                                                                            test_size=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svd= TruncatedSVD(100)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i'm not doing this right :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2747, 11651) (2747,)\n",
      "TFIDF Training set score: 0.8838733163451038\n",
      "\n",
      " TFIDF Test set score: 0.6741266375545851\n",
      "TFIDF Training set score: 0.9905351292318894\n",
      "\n",
      "TFIDF Test set score: 0.44759825327510916\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression()\n",
    "rfc2 = ensemble.RandomForestClassifier()\n",
    "\n",
    "train = lr2.fit(X_train_tfidf, y_train_tfidf)\n",
    "print(X_train_tfidf.shape, y_train_tfidf.shape)\n",
    "print('TFIDF Training set score:', lr2.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\n TFIDF Test set score:', lr2.score(X_test_tfidf, y_test_tfidf))\n",
    "\n",
    "\n",
    "train = rfc2.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('TFIDF Training set score:', rfc2.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTFIDF Test set score:', rfc2.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
